# LLM Preprocessing Examples

This document provides examples of using the LLM preprocessing features with the Edge TTS API.

## Overview

The API now supports two optional LLM preprocessing modes:

1. **Text Optimization for TTS** (`optimize_for_tts`): Cleans and optimizes input text for better TTS output
2. **SSML Markup Generation** (`add_ssml_markup`): Automatically adds SSML tags for natural pronunciation

Both features require an OpenAI-compatible LLM endpoint and API key.

## Configuration

You need to provide:
- `llm_api_key`: Your API key for the LLM service
- `llm_endpoint`: The OpenAI-compatible endpoint URL (e.g., `https://api.openai.com/v1/chat/completions`)

## Example 1: Text Optimization

Optimize text by replacing uncommon characters, simplifying lists, and expanding abbreviations.

```bash
curl -X POST https://your-worker.workers.dev/v1/audio/speech_subtitles \
  -H "Content-Type: application/json" \
  -d '{
    "input": "Hello! This is a test w/ some abbrev. & special chars #1",
    "voice": "en-US-EmmaMultilingualNeural",
    "llm_api_key": "sk-your-api-key",
    "llm_endpoint": "https://api.openai.com/v1/chat/completions",
    "optimize_for_tts": true
  }'
```

**Before:** `"Hello! This is a test w/ some abbrev. & special chars #1"`

**After (example):** `"Hello! This is a test with some abbreviations and special characters number one"`

## Example 2: SSML Markup Generation

Automatically add SSML tags for natural pauses, emphasis, and proper pronunciation.

```bash
curl -X POST https://your-worker.workers.dev/v1/audio/speech_subtitles \
  -H "Content-Type: application/json" \
  -d '{
    "input": "Hello, world! This is very important. The meeting is on January 15th at 3pm.",
    "voice": "en-US-EmmaMultilingualNeural",
    "llm_api_key": "sk-your-api-key",
    "llm_endpoint": "https://api.openai.com/v1/chat/completions",
    "add_ssml_markup": true
  }'
```

**Before:** `"Hello, world! This is very important. The meeting is on January 15th at 3pm."`

**After (example):**
```xml
<speak>
  Hello, world!
  <break strength="medium"/>
  This is <emphasis level="strong">very important</emphasis>.
  <break strength="medium"/>
  The meeting is on <say-as interpret-as="date" format="md">January 15th</say-as> 
  at <say-as interpret-as="time" format="hm">3pm</say-as>.
</speak>
```

## Example 3: Combined Processing

Use both optimization and SSML markup together for the best results.

```bash
curl -X POST https://your-worker.workers.dev/v1/audio/speech_subtitles \
  -H "Content-Type: application/json" \
  -d '{
    "input": "TODO: Call John @ 555-1234 re: Q1 results (ASAP!)",
    "voice": "en-US-EmmaMultilingualNeural",
    "llm_api_key": "sk-your-api-key",
    "llm_endpoint": "https://api.openai.com/v1/chat/completions",
    "optimize_for_tts": true,
    "add_ssml_markup": true
  }'
```

**Processing flow:**
1. First, text is optimized: `"TODO: Call John @ 555-1234 re: Q1 results (ASAP!)"` â†’ `"To do: Call John at five five five one two three four regarding quarter one results as soon as possible"`
2. Then, SSML markup is added with appropriate emphasis and breaks

## Example 4: Using with Raw Audio Endpoint

The LLM preprocessing also works with the `/v1/audio/speech` endpoint:

```bash
curl -X POST https://your-worker.workers.dev/v1/audio/speech \
  -H "Content-Type: application/json" \
  -d '{
    "input": "Check the README.md file ASAP!",
    "voice": "en-US-EmmaMultilingualNeural",
    "llm_api_key": "sk-your-api-key",
    "llm_endpoint": "https://api.openai.com/v1/chat/completions",
    "optimize_for_tts": true,
    "add_ssml_markup": true
  }' --output speech.mp3
```

## Using the Demo UI

The demo interface at `/` includes a toggleable LLM preprocessing section:

1. Check "ðŸ¤– Enable LLM Preprocessing"
2. Enter your LLM endpoint URL
3. Enter your API key
4. Select the desired preprocessing options:
   - âœ… Optimize text for TTS
   - âœ… Add SSML markup
5. Click "Generate Speech & Subtitles"

Your settings are automatically saved to LocalStorage for convenience.

## Error Handling

If LLM preprocessing fails, the API will return a 500 error with details:

```json
{
  "error": "LLM text optimization failed",
  "message": "LLM API request failed: 401 Unauthorized"
}
```

Common errors:
- Invalid API key
- Endpoint not reachable
- Invalid SSML generated by LLM
- LLM API rate limits exceeded

## System Prompts

### Text Optimization Prompt

The LLM uses a comprehensive system prompt to:
- Replace uncommon characters and symbols with spoken equivalents (@ â†’ "at", & â†’ "and", # â†’ "number")
- Expand abbreviations context-aware (Dr. â†’ Doctor, re: â†’ regarding, w/ â†’ with)
- Transform lists and bullet points into natural prose using connectors
- Handle numbers, dates, and phone numbers appropriately
- Fix typos and excessive punctuation
- Preserve proper nouns, brand names, and technical terms
- Maintain sentence boundaries and logical structure

### SSML Markup Prompt

The LLM uses a detailed system prompt with specific heuristics:

**Break Tags** - Strategic pauses:
- After sentences (500ms), commas (200ms), paragraphs (800ms)
- Before important information (strong strength)

**Emphasis Tags** - Highlighting key information:
- Strong emphasis for critical words
- Moderate for important points
- Reduced for parentheticals
- Limited to 2-3 per sentence to avoid over-markup

**Say-As Tags** - Accurate pronunciation:
- Dates, times, numbers (cardinal/ordinal)
- Phone numbers, currency
- Character-by-character for acronyms

**Prosody Tags** - Speech characteristics:
- Rate adjustments (slow for complex info, fast for asides)
- Pitch modulation (lower for warnings, higher for excitement)
- Volume control where appropriate

**Smart Heuristics**:
- Questions get upward pitch
- Exclamations add emphasis + breaks
- Punctuation-based break insertion
- Multi-digit numbers use say-as tags
- Acronyms (2-4 caps) spelled out

**Self-Closing Tags**:
- Uses proper self-closing format: `<break time="300ms"/>`
- Prevents validation errors from improperly closed tags

**Validation**:
- Ensures `<speak>` wrapper is present
- Validates tag balance (accounting for self-closing tags)
- Prevents malformed SSML from reaching TTS engine

## Best Practices

1. **Use text optimization** when dealing with:
   - Technical documentation with abbreviations
   - Lists and bullet points
   - Text with special characters or symbols
   - Mixed formatting (markdown, etc.)

2. **Use SSML markup** when you need:
   - Natural pauses and pacing
   - Emphasis on specific words
   - Proper pronunciation of dates, times, numbers
   - Enhanced expressiveness

3. **Use both together** for the best results with complex text

4. **Keep API keys secure**: Store them in environment variables or LocalStorage, never in code

5. **Handle errors gracefully**: Always check for LLM preprocessing errors and provide fallbacks

## Alternative LLM Providers

The API works with any OpenAI-compatible endpoint:

- **OpenAI**: `https://api.openai.com/v1/chat/completions`
- **Azure OpenAI**: `https://YOUR-RESOURCE.openai.azure.com/openai/deployments/YOUR-DEPLOYMENT/chat/completions?api-version=2024-02-15-preview`
- **Local models** (via LM Studio, Ollama, etc.): `http://localhost:1234/v1/chat/completions`
- **Other providers**: Any service that implements the OpenAI chat completions API

## Performance Considerations

- LLM preprocessing adds latency (typically 1-3 seconds per request)
- Consider caching optimized/marked-up text if processing the same content repeatedly
- Use smaller/faster models if latency is critical
- The optimization runs sequentially (optimize â†’ add SSML) when both are enabled
